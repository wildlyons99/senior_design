{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a single perceptron model that DOES NOT use PyTorch!\n",
    "\n",
    "Propagation and optimization functions are the same as slideshow, except our activation function is not a sigmoid but a unit step (so we ignore its derivative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x, y, weights, bias):\n",
    "    \"\"\"\n",
    "    x: training data as a vector (nparray), where each value corresponds\n",
    "        to a feature's value\n",
    "    y: label (0 or 1)\n",
    "    weights: weights of the perceptron\n",
    "    bias: bias\n",
    "    \"\"\"\n",
    "    y_pred = predict(x, weights, bias)\n",
    "    loss = (y_pred - y)**2\n",
    "    d_loss = 2*(y_pred - y)\n",
    "\n",
    "    return y_pred, loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_perceptron(x, y, learning_rate,  maxEpochs, ):\n",
    "    \"\"\"\n",
    "    Optimizes the Perceptron's weights by looping over the same steps for the specified number of epochs.\n",
    "    Steps:\n",
    "    1. Forward propagate data point\n",
    "    2. Backpropagate\n",
    "    3. Update weights\n",
    "    4. Check stop conditions while looping\n",
    "    \"\"\"\n",
    "    epoch = 0\n",
    "    error = 999\n",
    "    weights = np.random.rand(x.shape[1])\n",
    "    bias = np.random.rand()\n",
    "\n",
    "    errors = list()\n",
    "    epochs = list()\n",
    "\n",
    "    # Loop until stop conditions are met\n",
    "    while (epoch <= maxEpochs) and (error > 9e-4):\n",
    "\n",
    "        loss_ = 0\n",
    "        # Loop over every data point\n",
    "        for i in range(x.shape[0]):\n",
    "\n",
    "            # Forward Propagation on each data point\n",
    "            y_pred, loss, d_loss = forward_propagation(x[i], y[i], weights, bias)\n",
    "\n",
    "            # Backpropagation\n",
    "            partial_derivates = backpropagation(x[i], d_loss)\n",
    "\n",
    "            # Learn by updating the weights of the perceptron\n",
    "            weights = weights - (learning_rate * np.array(partial_derivates))\n",
    "\n",
    "        # Evaluate the results\n",
    "        for index, feature_value_test in enumerate(x):\n",
    "            y_pred, loss, d_loss = forward_propagation(feature_value_test, y[index], weights, bias)\n",
    "            loss_ += loss\n",
    "\n",
    "        errors.append(loss_/len(x))\n",
    "        epochs.append(epoch)\n",
    "        error = errors[-1]\n",
    "        epoch += 1\n",
    "\n",
    "        print('Epoch {}. loss: {}'.format(epoch, errors[-1]))\n",
    "\n",
    "\n",
    "    return weights, bias, errors\n",
    "\n",
    "# def optimize_perceptron(x, y, learning_rate, maxEpochs, ):\n",
    "#     \"\"\"\n",
    "#     Optimizes the Perceptron's weights by looping over the same steps for the specified number of epochs.\n",
    "#     Steps:\n",
    "#     1. Forward propagate data point\n",
    "#     2. Backpropagate\n",
    "#     3. Update weights\n",
    "#     4. Check stop conditions while looping\n",
    "#     \"\"\"\n",
    "#     epoch = 0\n",
    "#     error = 999\n",
    "#     weights = np.random.rand(x.shape[1])  # initialize weights randomly\n",
    "#     bias = np.random.rand()  # initialize bias randomly\n",
    "\n",
    "#     errors = list()\n",
    "#     epochs = list()\n",
    "\n",
    "#     # Loop until stop conditions are met\n",
    "#     while (epoch <= maxEpochs) and (error > 9e-4):\n",
    "\n",
    "#         loss_ = 0\n",
    "#         # Loop over every data point\n",
    "#         for i in range(x.shape[0]):\n",
    "\n",
    "#             # Forward Propagation on each data point\n",
    "#             y_pred, loss, d_loss = forward_propagation(x[i], y[i], weights, bias)\n",
    "\n",
    "#             # Backpropagation\n",
    "#             partial_derivates = backpropagation(x[i], d_loss)\n",
    "\n",
    "#             # Learn by updating the weights of the perceptron\n",
    "#             weights = weights - (learning_rate * np.array(partial_derivates))\n",
    "\n",
    "#             # Ensure weights remain positive\n",
    "#             weights = np.clip(weights, 0, None)\n",
    "\n",
    "#         # Evaluate the results\n",
    "#         for index, feature_value_test in enumerate(x):\n",
    "#             y_pred, loss, d_loss = forward_propagation(feature_value_test, y[index], weights, bias)\n",
    "#             loss_ += loss\n",
    "\n",
    "#         errors.append(loss_ / len(x))\n",
    "#         epochs.append(epoch)\n",
    "#         error = errors[-1]\n",
    "#         epoch += 1\n",
    "\n",
    "#         print('Epoch {}. loss: {}'.format(epoch, errors[-1]))\n",
    "\n",
    "#     return weights, bias, errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(prediction):\n",
    "    \"\"\"\n",
    "    Receives the output of the perceptron's function as parameter, and applies the\n",
    "    activation function on it.\n",
    "    In this simple model, the activation function is a unit step which classifies\n",
    "    negative inputs as 0 and positive inputs as 1.\n",
    "    \"\"\"\n",
    "    if prediction >= 0.5:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def predict(x, weights, bias):\n",
    "    \"\"\"\n",
    "    Predicts the class of a given data point (x) by running the input through\n",
    "    the neuron (dot product) and then applying the activation function.\n",
    "    \"\"\"\n",
    "    prediction = np.dot(weights, x) + bias\n",
    "    prediction = activation_function(prediction)\n",
    "\n",
    "    return (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(x, d_loss):\n",
    "    \"\"\"\n",
    "    Performs the Backpropagation step on a given data point.\n",
    "    Receives as input the data point, the Perceptron's weights and the partial derivative of the loss\n",
    "    over the predicted y.\n",
    "    The received derivative is used to calculate the partial derivative of the loss over the weight of each feature.\n",
    "    A list with the partial derivatives of the loss over each weight is returned.\n",
    "    \"\"\"\n",
    "    partial_derivates = list()\n",
    "    for feature_value in x:\n",
    "        partial_derivates.append(d_loss*feature_value)\n",
    "\n",
    "    return partial_derivates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8816, 785)\n",
      "[0 1]\n",
      "(6612, 784)\n",
      "(2204, 784)\n",
      "(6612,)\n",
      "(2204,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data_mnist.zip')\n",
    "\n",
    "# Take only data with labels 1\n",
    "data_ones = data[data['label'] == 1]\n",
    "\n",
    "# Take only data with labels 0\n",
    "data_zeros = data[data['label'] == 0]\n",
    "\n",
    "# If you want to change either digit, just change the label value to either a 0 or a 1 so the math works out\n",
    "# Ex. data_zeros = data[data['label'] == 7]\n",
    "#     data_zeros['label'] = 0\n",
    "\n",
    "# Concatenate instances with label 0 and 1\n",
    "data = pd.concat([data_ones, data_zeros])\n",
    "print(data.shape)\n",
    "print(np.unique(data['label'].to_numpy()))\n",
    "\n",
    "# # Split dataset with 75% training data and 25% test data\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=1, shuffle=True)\n",
    "\n",
    "# Split datasets into features and labels\n",
    "x_train = train_data.drop('label', axis=1).to_numpy()\n",
    "x_test = test_data.drop('label', axis=1).to_numpy()\n",
    "y_train = train_data['label'].to_numpy()\n",
    "y_test = test_data['label'].to_numpy()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Rescale data points to values between 0 and 1 (pixels are originally 0-255)\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkdata(data, res):\n",
    "    \"\"\"\n",
    "    Reformats the input data at a lower resolution.\n",
    "    data: Our input data matrix\n",
    "    res:  The resolution (must be a factor of 28)\n",
    "    \"\"\"\n",
    "    data = data[0:].reshape([data.shape[0], 28, 28])\n",
    "    data = data.reshape(data.shape[0], res, int(28 / res), res, int(28 / res)).sum(axis=2).sum(axis=3)\n",
    "    data = data / ((28 / res)**2)\n",
    "    data = data[0:].reshape(data.shape[0], res**2)\n",
    "    return data\n",
    "\n",
    "def shrinkpoint(data, res):\n",
    "    \"\"\"\n",
    "    Same as shrinkdata, but for a single 784 pixel image\n",
    "    \"\"\"\n",
    "    data = data.reshape([28, 28])\n",
    "    data = data.reshape(res, int(28 / res), res, int(28 / res)).sum(axis=1).sum(axis=2)\n",
    "    data = data / ((28 / res)**2)\n",
    "    data = data.reshape(res**2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a39b4b8b90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[205].reshape([28, 28]), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a39b709590>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resolution = 7 # 4x4 image resolution\n",
    "x_train_shrunk = shrinkdata(x_train, resolution)\n",
    "x_test_shrunk = shrinkdata(x_test, resolution)\n",
    "\n",
    "plt.imshow(x_train_shrunk[205].reshape([resolution, resolution]), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(x_test, y_test, weights, bias):\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for sample, label in zip(x_test, y_test):\n",
    "\n",
    "        prediction = predict(sample, weights, bias)\n",
    "\n",
    "        if prediction == label:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(x_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. loss: 0.12915910465819722\n",
      "Epoch 2. loss: 0.0911978221415608\n",
      "Epoch 3. loss: 0.07153660012099214\n",
      "Epoch 4. loss: 0.062008469449485785\n",
      "Epoch 5. loss: 0.059437386569872956\n",
      "Epoch 6. loss: 0.05716878402903811\n",
      "Epoch 7. loss: 0.055505142165759226\n",
      "Epoch 8. loss: 0.05369026013309135\n",
      "Epoch 9. loss: 0.05369026013309135\n",
      "Epoch 10. loss: 0.052177858439201454\n",
      "Epoch 11. loss: 0.05127041742286751\n",
      "Epoch 12. loss: 0.05066545674531155\n",
      "Epoch 13. loss: 0.05021173623714459\n",
      "Epoch 14. loss: 0.050060496067755596\n",
      "Epoch 15. loss: 0.04869933454325469\n",
      "Epoch 16. loss: 0.04824561403508772\n",
      "Epoch 17. loss: 0.04764065335753176\n",
      "Epoch 18. loss: 0.0470356926799758\n",
      "Epoch 19. loss: 0.04673321234119782\n",
      "Epoch 20. loss: 0.04658197217180883\n",
      "Epoch 21. loss: 0.04673321234119782\n",
      "Epoch 22. loss: 0.046430732002419844\n",
      "Epoch 23. loss: 0.046430732002419844\n",
      "Epoch 24. loss: 0.045674531155474894\n",
      "Epoch 25. loss: 0.04506957047791894\n",
      "Epoch 26. loss: 0.044615849969751965\n",
      "Epoch 27. loss: 0.044615849969751965\n",
      "Epoch 28. loss: 0.04446460980036298\n",
      "Epoch 29. loss: 0.04401088929219601\n",
      "Epoch 30. loss: 0.04310344827586207\n",
      "Epoch 31. loss: 0.04310344827586207\n",
      "Epoch 32. loss: 0.04295220810647308\n",
      "Epoch 33. loss: 0.04370840895341803\n",
      "Epoch 34. loss: 0.04446460980036298\n",
      "Epoch 35. loss: 0.04370840895341803\n",
      "Epoch 36. loss: 0.043557168784029036\n",
      "Epoch 37. loss: 0.042800967937084086\n",
      "Epoch 38. loss: 0.04340592861464005\n",
      "Epoch 39. loss: 0.042800967937084086\n",
      "Epoch 40. loss: 0.04249848759830611\n",
      "Epoch 41. loss: 0.04249848759830611\n",
      "Epoch 42. loss: 0.04204476709013914\n",
      "Epoch 43. loss: 0.04204476709013914\n",
      "Epoch 44. loss: 0.04219600725952813\n",
      "Epoch 45. loss: 0.041742286751361164\n",
      "Epoch 46. loss: 0.04159104658197217\n",
      "Epoch 47. loss: 0.04159104658197217\n",
      "Epoch 48. loss: 0.0411373260738052\n",
      "Epoch 49. loss: 0.041439806412583186\n",
      "Epoch 50. loss: 0.040986085904416214\n",
      "Epoch 51. loss: 0.04128856624319419\n",
      "Epoch 52. loss: 0.041742286751361164\n",
      "Epoch 53. loss: 0.0411373260738052\n",
      "Epoch 54. loss: 0.040986085904416214\n",
      "Epoch 55. loss: 0.041439806412583186\n",
      "Epoch 56. loss: 0.0411373260738052\n",
      "Epoch 57. loss: 0.040986085904416214\n",
      "Epoch 58. loss: 0.04128856624319419\n",
      "Epoch 59. loss: 0.04128856624319419\n",
      "Epoch 60. loss: 0.0411373260738052\n",
      "Epoch 61. loss: 0.04128856624319419\n",
      "Epoch 62. loss: 0.04128856624319419\n",
      "Epoch 63. loss: 0.04128856624319419\n",
      "Epoch 64. loss: 0.04128856624319419\n",
      "Epoch 65. loss: 0.0411373260738052\n",
      "Epoch 66. loss: 0.040986085904416214\n",
      "Epoch 67. loss: 0.04083484573502722\n",
      "Epoch 68. loss: 0.04083484573502722\n",
      "Epoch 69. loss: 0.04053236539624924\n",
      "Epoch 70. loss: 0.04038112522686026\n",
      "Epoch 71. loss: 0.04038112522686026\n",
      "Epoch 72. loss: 0.04038112522686026\n",
      "Epoch 73. loss: 0.04038112522686026\n",
      "Epoch 74. loss: 0.04038112522686026\n",
      "Epoch 75. loss: 0.04038112522686026\n",
      "Epoch 76. loss: 0.040229885057471264\n",
      "Epoch 77. loss: 0.04038112522686026\n",
      "Epoch 78. loss: 0.04053236539624924\n",
      "Epoch 79. loss: 0.04083484573502722\n",
      "Epoch 80. loss: 0.04083484573502722\n",
      "Epoch 81. loss: 0.040986085904416214\n",
      "Epoch 82. loss: 0.040986085904416214\n",
      "Epoch 83. loss: 0.0411373260738052\n",
      "Epoch 84. loss: 0.0411373260738052\n",
      "Epoch 85. loss: 0.0411373260738052\n",
      "Epoch 86. loss: 0.040683605565638235\n",
      "Epoch 87. loss: 0.04083484573502722\n",
      "Epoch 88. loss: 0.040986085904416214\n",
      "Epoch 89. loss: 0.0411373260738052\n",
      "Epoch 90. loss: 0.040986085904416214\n",
      "Epoch 91. loss: 0.040986085904416214\n",
      "Epoch 92. loss: 0.040986085904416214\n",
      "Epoch 93. loss: 0.04083484573502722\n",
      "Epoch 94. loss: 0.04083484573502722\n",
      "Epoch 95. loss: 0.04083484573502722\n",
      "Epoch 96. loss: 0.04053236539624924\n",
      "Epoch 97. loss: 0.04038112522686026\n",
      "Epoch 98. loss: 0.04038112522686026\n",
      "Epoch 99. loss: 0.04007864488808228\n",
      "Epoch 100. loss: 0.040229885057471264\n",
      "Epoch 101. loss: 0.040229885057471264\n"
     ]
    }
   ],
   "source": [
    "weights, bias, errors = optimize_perceptron(x_train_shrunk, y_train, learning_rate = 0.001, maxEpochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9632486388384754\n"
     ]
    }
   ],
   "source": [
    "acc = calculate_accuracy(x_test_shrunk, y_test, weights, bias)\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.20621611e-01 3.54929248e-01 6.97548245e-01 7.48796413e-01\n",
      "  3.04907451e-01 1.78277966e-01 1.97674401e-01]\n",
      " [5.23973231e-01 8.42156863e-04 2.26274510e-03 7.18480392e-03\n",
      "  3.20784314e-03 0.00000000e+00 0.00000000e+00]\n",
      " [1.22102927e-01 4.54411765e-04 0.00000000e+00 1.73039216e-04\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.14546719e-01 0.00000000e+00 0.00000000e+00 4.93467817e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.67552106e-01 0.00000000e+00 0.00000000e+00 2.56361836e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.69375380e-01 0.00000000e+00 2.50980392e-04 6.39117647e-03\n",
      "  3.43725490e-03 1.70588235e-03 7.48536122e-01]\n",
      " [6.99912108e-01 2.05294118e-03 4.68815011e-02 9.14068627e-02\n",
      "  7.54409411e-01 2.70158490e-01 6.89963206e-01]]\n"
     ]
    }
   ],
   "source": [
    "weights.resize((resolution, resolution))\n",
    "plt.imshow(weights, cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
